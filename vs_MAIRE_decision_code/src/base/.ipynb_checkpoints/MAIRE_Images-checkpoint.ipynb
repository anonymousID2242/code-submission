{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "WPyv-Po-dXZH",
    "outputId": "b092f49a-2f97-4cb5-faa9-1e14936fd414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘output_images’: File exists\n",
      "mkdir: cannot create directory ‘frames’: File exists\n",
      "mkdir: cannot create directory ‘animations’: File exists\n",
      "Requirement already satisfied: imageio in /home/viraat/anaconda3/envs/nikhil/lib/python3.6/site-packages (2.6.1)\n",
      "Requirement already satisfied: numpy in /home/viraat/anaconda3/envs/nikhil/lib/python3.6/site-packages (from imageio) (1.17.3)\n",
      "Requirement already satisfied: pillow in /home/viraat/anaconda3/envs/nikhil/lib/python3.6/site-packages (from imageio) (6.2.1)\n"
     ]
    }
   ],
   "source": [
    "!mkdir output_images\n",
    "!mkdir frames\n",
    "!mkdir animations\n",
    "!pip install imageio\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Ps79dKL25gle",
    "outputId": "a35e2ac9-25a8-4677-e607-58b8e44f2272"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ILSVRC2012_test_00031441.JPEG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cf4cdbe6964b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ILSVRC2012_test_00031441.JPEG\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nikhil/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nikhil/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ILSVRC2012_test_00031441.JPEG'"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "img_name = \"ILSVRC2012_test_00031441.JPEG\"\n",
    "model = VGG16()\n",
    "image = load_img(img_name, target_size=(224, 224))\n",
    "image = img_to_array(image)\n",
    "images = np.zeros((1, 224, 224, 3))\n",
    "images[0, :, :, :] = image[:, :, :]\n",
    "images = preprocess_input(images)\n",
    "predictions = model.predict(images)\n",
    "labels = decode_predictions(predictions)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "id": "XhiHUjWvY8sD",
    "outputId": "6bfceb5c-d2d4-42ad-8e85-4503524ec849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'output_images/*': No such file or directory\n",
      "rm: cannot remove 'frames/*': No such file or directory\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'explain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-733e97a10edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexplain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexplain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'explain'"
     ]
    }
   ],
   "source": [
    "!rm output_images/*\n",
    "!rm frames/*\n",
    "from skimage.transform import resize\n",
    "from skimage.segmentation import slic, felzenszwalb\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras import backend as K\n",
    "from explain import explain\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import matplotlib.colors as mcolors\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "numSegments = 100\n",
    "path = \"output_images/\"\n",
    "img_name = \"dog.jpg\"\n",
    "object_label = \"beagle\"\n",
    "cut_off = 0.90\n",
    "images_anim = []\n",
    "image1 = img_as_float(io.imread(img_name))\n",
    "original_image_dims = image1.shape\n",
    "def plot_function(iteration, l_vals, u_vals):\n",
    "  return\n",
    "  final_image = np.zeros((224, 224, 3), dtype = \"uint8\")\n",
    "  final_image[:, :, :] = image[:, :, :]\n",
    "  for i in range(numSegments):\n",
    "    if l_vals[i] < (1.0 / 3):\n",
    "      final_image[masks[i, :, :], :] = 255\n",
    "  cv2.imwrite(\"frames/\" + str(iteration) + \".jpg\", cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR))\n",
    "  images_anim.append(imageio.imread(\"frames/\" + str(iteration) + \".jpg\"))\n",
    "#img_as_float(cv2.resize(io.imread(img_name), (224, 224)))\n",
    "#segments = slic(image1, n_segments = 200, sigma = 0.1)\n",
    "segments = felzenszwalb(image1, scale = 100, sigma = 0.5, min_size = numSegments)\n",
    "\n",
    "#for i in range(224):\n",
    "#  for j in range(224):\n",
    "#    segments[i, j] = i*224 + j\n",
    "#slic(image1, n_segments = numSegments, sigma = 5)\n",
    "numSegments = np.max(segments) + 1\n",
    "print(numSegments)\n",
    "#model = VGG16()\n",
    "#model.summary()\n",
    "image = load_img(img_name, target_size=(224, 224))\n",
    "image = img_to_array(image)\n",
    "orig_image = load_img(img_name)\n",
    "orig_image = img_to_array(orig_image)\n",
    "masks = np.zeros((numSegments, original_image_dims[0], original_image_dims[1]), dtype = bool)\n",
    "for i in range(numSegments):\n",
    "  masks[i, :, :] = (segments == i)\n",
    "class image_class(explain):\n",
    "  iteration = -1\n",
    "  def sampling(self, num_sampled_points):\n",
    "    self.iteration += 1\n",
    "    if (self.iteration % 1000 == 0):\n",
    "      #sample_points(num_sampled_points, self.temp_l_vec_values)\n",
    "      sample_points_1(num_sampled_points)\n",
    "    #samples = np.random.randint(2, size = (num_sampled_points, numSegments))\n",
    "    #odds = [1] * 50 + [2] * 40 + [3] * 10\n",
    "    #indices = np.random.randint(1, total_points, (num_sampled_points))\n",
    "    #indices[0] = 0\n",
    "    #return input_for_explanations[indices, :], class_labels[indices]\n",
    "    return input_for_explanations, class_labels\n",
    "def sample_points_2(num_sampled_points):\n",
    "  global input_for_explanations, class_labels\n",
    "  samples = np.ones((num_sampled_points, numSegments))\n",
    "  for i in range(numSegments):\n",
    "    for j in range(int(num_sampled_points / numSegments)):\n",
    "      samples[np.random.randint(0, num_sampled_points), i] = 0\n",
    "  #for i in range(num_sampled_points):\n",
    "  #  for j in range(int(0.1 * numSegments)):\n",
    "  #    samples[i, random.randint(0, numSegments - 1)] = 0\n",
    "  samples[0, :] = 1\n",
    "  input_for_explanations = samples[:, :] * (1.0 / 3) + (1.0 / 3)\n",
    "  images = np.zeros((num_sampled_points, 224, 224, 3))\n",
    "  samples_boolean = samples.astype(bool)\n",
    "  for i in range(num_sampled_points):\n",
    "    images[i, :, :, :] = image[:, :, :]\n",
    "    images[i, np.any(masks[~samples_boolean[i, :], :, :], 0), :] = 0\n",
    "  images = preprocess_input(images)\n",
    "\n",
    "  #all_predictions = np.zeros((num_sampled_points, 1000))\n",
    "  #for i in range(0, num_sampled_points, 100):\n",
    "  #  all_predictions[i:i+100, :] = model.predict(images[i:i+100, :, :, :])\n",
    "  all_predictions = model.predict(images)\n",
    "  labels = decode_predictions(all_predictions)\n",
    "  class_labels = np.zeros((num_sampled_points, ))\n",
    "  for i in range(num_sampled_points):\n",
    "    for j in range(len(labels[i])):\n",
    "      if labels[i][j][1] == object_label and labels[i][j][2] >= cut_off:\n",
    "        class_labels[i] = 1\n",
    "        break\n",
    "def sample_points_1(num_sampled_points):\n",
    "  global input_for_explanations, class_labels\n",
    "  samples = np.ones((num_sampled_points, numSegments))\n",
    "  for i in range(num_sampled_points):\n",
    "    #parameters_to_be_flipped = np.random.choice(numSegments, int(0.35 * numSegments), replace = False)\n",
    "    #samples[i, parameters_to_be_flipped] = 1 - samples[i, parameters_to_be_flipped]\n",
    "    for j in range(int(0.35 * numSegments)):\n",
    "      samples[i, random.randint(0, numSegments - 1)] = 0\n",
    "  samples[0, :] = 1\n",
    "  input_for_explanations = samples[:, :] * (1.0 / 3) + (1.0 / 3)\n",
    "  images = np.zeros((num_sampled_points, 224, 224, 3))\n",
    "  samples_boolean = samples.astype(bool)\n",
    "  for i in range(num_sampled_points):\n",
    "    images[i, :, :, :] = image[:, :, :]\n",
    "    images[i, cv2.resize(np.any(masks[~samples_boolean[i, :], :, :], 0).astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "  images = preprocess_input(images)\n",
    "\n",
    "  #all_predictions = np.zeros((num_sampled_points, 1000))\n",
    "  #for i in range(0, num_sampled_points, 100):\n",
    "  #  all_predictions[i:i+100, :] = model.predict(images[i:i+100, :, :, :])\n",
    "  all_predictions = model.predict(images)\n",
    "  labels = decode_predictions(all_predictions)\n",
    "  class_labels = np.zeros((num_sampled_points, ))\n",
    "  for i in range(num_sampled_points):\n",
    "    for j in range(len(labels[i])):\n",
    "      if labels[i][j][1] == object_label and labels[i][j][2] >= cut_off:\n",
    "        class_labels[i] = 1\n",
    "        break\n",
    "def sample_points(num_sampled_points, l_vec):\n",
    "  global input_for_explanations, class_labels\n",
    "  samples = np.ones((num_sampled_points, numSegments))\n",
    "  for i in range(numSegments):\n",
    "    if l_vec[i] < (1.0 / 3):\n",
    "      samples[0:(num_sampled_points), i] = np.random.randint(0, 2, ((num_sampled_points), ))\n",
    "      #samples[(num_sampled_points/2):num_sampled_points, i] = 0\n",
    "  for i in range(num_sampled_points / 2):\n",
    "    parameters_to_be_flipped = np.random.choice(numSegments, np.random.randint(1, int(0.5 * numSegments)))\n",
    "    samples[i, parameters_to_be_flipped] = 1 - samples[i, parameters_to_be_flipped]\n",
    "    #np.random.randint(1, int(0.05 * numSegments))\n",
    "    #parameters_to_be_flipped = np.random.choice(numSegments, 1)\n",
    "    #samples[i, parameters_to_be_flipped] = 1 - samples[i, parameters_to_be_flipped]\n",
    "    #for j in range(random.randint(1, int(0.3 * numSegments))):\n",
    "    #  segmentNumber = random.randint(0, numSegments - 1)\n",
    "    #  samples[i, segmentNumber] = 1 - samples[i, segmentNumber]\n",
    "  samples[0, :] = 1\n",
    "  input_for_explanations = np.zeros((num_sampled_points, numSegments))\n",
    "  input_for_explanations[:, :] = samples[:, :] * (1.0 / 3) + (1.0 / 3)\n",
    "  images = np.zeros((num_sampled_points, 224, 224, 3))\n",
    "  samples_boolean = samples.astype(bool)\n",
    "  for i in range(num_sampled_points):\n",
    "    images[i, :, :, :] = image[:, :, :]\n",
    "    images[i, cv2.resize(np.any(masks[~samples_boolean[i, :], :, :], 0).astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "  images = preprocess_input(images)\n",
    "\n",
    "  all_predictions = np.zeros((num_sampled_points, 1000))\n",
    "  for i in range(0, num_sampled_points, 100):\n",
    "    all_predictions[i:i+100, :] = model.predict(images[i:i+100, :, :, :])\n",
    "  labels = decode_predictions(all_predictions)\n",
    "  class_labels = np.zeros((num_sampled_points, ))\n",
    "  for i in range(num_sampled_points):\n",
    "    for j in range(len(labels[i])):\n",
    "      if labels[i][j][1] == object_label and labels[i][j][2] >= cut_off:\n",
    "        class_labels[i] = 1\n",
    "        break\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for run in range(1):\n",
    "  image_object = image_class(np.ones(numSegments, ) * (2.0 / 3), 1000, np.array([[1]]), 100, 100, 0.95, plot_function)\n",
    "  model = VGG16()\n",
    "  image_object.fit_explanation(5000)\n",
    "  final_image = np.zeros((original_image_dims[0], original_image_dims[1], 3), dtype = \"uint8\")\n",
    "  final_image[:, :, :] = orig_image[:, :, :]\n",
    "  test_image = np.zeros((224, 224, 3))\n",
    "  test_image[:, :, :] = image[:, :, :]\n",
    "  for i in range(numSegments):\n",
    "    if image_object.l_vec_values[i] < (1.0 / 3):\n",
    "      final_image[masks[i, :, :], :] = 255\n",
    "      test_image[cv2.resize(masks[i, :, :].astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "  test_images = np.zeros((1, 224, 224, 3))\n",
    "  test_images[0, :, :, :] = test_image[:, :, :]\n",
    "  test_images = preprocess_input(test_images)\n",
    "  print(decode_predictions(model.predict(test_images)))\n",
    "  valid_superpixels = np.ones((numSegments, ), dtype = bool)\n",
    "  valid_superpixels[image_object.l_vec_values < (1.0 / 3)] = 0\n",
    "  cv2.imwrite(path + str(run) + \"_Explanation.jpg\", cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR))\n",
    "  superpixel_removal_order = image_object.greedy_select(numSegments, list(valid_superpixels))\n",
    "  map_importance = np.zeros((original_image_dims[0], original_image_dims[1]))\n",
    "  for i in range(len(superpixel_removal_order)):\n",
    "    map_importance[segments == superpixel_removal_order[i]] = (i + 1) * 1.0 / len(superpixel_removal_order)\n",
    "  heatmap = cv2.applyColorMap(np.uint8(255 * (1 - map_importance)), cv2.COLORMAP_JET)\n",
    "  image_plus_heatmap = cv2.addWeighted(np.uint8(orig_image), 0.2, heatmap, 0.8, 0)\n",
    "  ax.imshow(image_plus_heatmap / 255.0)\n",
    "  plt.axis(\"off\")\n",
    "  plt.savefig(path + str(run) + \"_Heat_Map.jpg\", bbox_inches = \"tight\")\n",
    "  points_graph = 10\n",
    "  images_for_prediction_anchor = np.zeros(((len(superpixel_removal_order) + 1) * points_graph, 224, 224, 3))\n",
    "  images_for_prediction_random = np.zeros(((len(superpixel_removal_order) + 1) * points_graph, 224, 224, 3))\n",
    "  x_anchor = []\n",
    "  x_random = []\n",
    "  y_anchor = []\n",
    "  y_random = []\n",
    "  for i in range(0, len(superpixel_removal_order) + 1):\n",
    "    for j in range(0, points_graph):\n",
    "      images_for_prediction_anchor[i * points_graph + j, :, :, :] = image[:, :, :]\n",
    "      images_for_prediction_random[i * points_graph + j, :, :, :] = image[:, :, :]\n",
    "      random_superpixels = np.random.choice(numSegments, i, replace = False)\n",
    "      anchor_superpixels = np.random.choice(superpixel_removal_order, i, replace = False)\n",
    "      for k in anchor_superpixels:\n",
    "        images_for_prediction_anchor[i * points_graph + j, cv2.resize(masks[k, :, :].astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "      for k in random_superpixels:\n",
    "        images_for_prediction_random[i * points_graph + j, cv2.resize(masks[k, :, :].astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "  images_for_prediction_anchor = preprocess_input(images_for_prediction_anchor)\n",
    "  images_for_prediction_random = preprocess_input(images_for_prediction_random)\n",
    "  predictions_anchor = model.predict(images_for_prediction_anchor)\n",
    "  predictions_random = model.predict(images_for_prediction_random)\n",
    "  decoded_anchor = decode_predictions(predictions_anchor, top = 1000)\n",
    "  decoded_random = decode_predictions(predictions_random, top = 1000)\n",
    "  for i in range(0, len(superpixel_removal_order) + 1):\n",
    "    for j in range(0, points_graph):\n",
    "      x_anchor.append(i)\n",
    "      for k in decoded_anchor[i * points_graph + j]:\n",
    "        if k[1] == object_label:\n",
    "          y_anchor.append(k[2])\n",
    "          break\n",
    "  for i in range(0, len(superpixel_removal_order) + 1):\n",
    "    for j in range(0, points_graph):\n",
    "      x_random.append(i)\n",
    "      for k in decoded_random[i * points_graph + j]:\n",
    "        if k[1] == object_label:\n",
    "          y_random.append(k[2])\n",
    "          break\n",
    "  y_anchor_mean = []\n",
    "  x_mean = []\n",
    "  y_random_mean = []\n",
    "  y_anchor_std = []\n",
    "  y_random_std = []\n",
    "  i = 0\n",
    "  while i < len(y_anchor):\n",
    "    y_anchor_mean.append(np.mean(y_anchor[i:i + points_graph]))\n",
    "    y_random_mean.append(np.mean(y_random[i:i + points_graph]))\n",
    "    y_anchor_std.append(np.std(y_anchor[i:i + points_graph]))\n",
    "    y_random_std.append(np.std(y_random[i:i + points_graph]))\n",
    "    x_mean.append(i / points_graph)\n",
    "    i += points_graph\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  (_, caps, _) = plt.errorbar(x_mean, y_anchor_mean, y_anchor_std, marker = \"o\", color = \"red\", capsize = 5)\n",
    "  for cap in caps:\n",
    "    cap.set_markeredgewidth(1)\n",
    "  (_, caps, _) = plt.errorbar(x_mean, y_random_mean, y_random_std, marker = \"o\", color = \"blue\", capsize = 5)\n",
    "  for cap in caps:\n",
    "    cap.set_markeredgewidth(1)\n",
    "  plt.axis(\"on\")\n",
    "  plt.savefig(path + str(run) + \"_Probability.jpg\", bbox_inches = \"tight\")\n",
    "  points_graph = 1\n",
    "  images_for_prediction_anchor = np.zeros(((len(superpixel_removal_order) + 1) * points_graph, 224, 224, 3))\n",
    "  images_for_prediction_random = np.zeros(((len(superpixel_removal_order) + 1) * points_graph, 224, 224, 3))\n",
    "  x_anchor = []\n",
    "  y_anchor = []\n",
    "  import copy\n",
    "  superpixel_reverse = copy.deepcopy(superpixel_removal_order)\n",
    "  superpixel_reverse.reverse()\n",
    "  for i in range(0, len(superpixel_removal_order) + 1):\n",
    "    for j in range(0, points_graph):\n",
    "      images_for_prediction_anchor[i * points_graph + j, :, :, :] = image[:, :, :]\n",
    "      anchor_superpixels = superpixel_reverse[0:i]\n",
    "      for k in anchor_superpixels:\n",
    "        images_for_prediction_anchor[i * points_graph + j, cv2.resize(masks[k, :, :].astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "  images_for_prediction_anchor = preprocess_input(images_for_prediction_anchor)\n",
    "  predictions_anchor = model.predict(images_for_prediction_anchor)\n",
    "  decoded_anchor = decode_predictions(predictions_anchor, top = 1000)\n",
    "  for i in range(0, len(superpixel_removal_order) + 1):\n",
    "    for j in range(0, points_graph):\n",
    "      x_anchor.append(i)\n",
    "      for k in decoded_anchor[i * points_graph + j]:\n",
    "        if k[1] == object_label:\n",
    "          y_anchor.append(k[2])\n",
    "          break\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  plt.plot(x_anchor, y_anchor, marker = \"o\")\n",
    "  plt.axis(\"on\")\n",
    "  plt.savefig(path + str(run) + \"_Greedy.jpg\", bbox_inches = \"tight\")\n",
    "  tf.reset_default_graph()\n",
    "  K.clear_session()\n",
    "imageio.mimsave(\"animations/animation.gif\", images_anim, loop = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1555
    },
    "colab_type": "code",
    "id": "UrChvdK6s-bY",
    "outputId": "dd04eeec-12c5-4316-c226-56ab5fb1c201"
   },
   "outputs": [],
   "source": [
    "!rm output_images/*\n",
    "!rm frames/*\n",
    "from skimage.transform import resize\n",
    "from skimage.segmentation import slic, felzenszwalb\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras import backend as K\n",
    "from explain_viz import explain\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import matplotlib.colors as mcolors\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "numSegments = 100\n",
    "path = \"output_images/\"\n",
    "img_name = \"dog.jpg\"\n",
    "object_label = \"beagle\"\n",
    "cut_off = 0.90\n",
    "images_anim = []\n",
    "image1 = img_as_float(io.imread(img_name))\n",
    "original_image_dims = image1.shape\n",
    "def plot_function(iteration, l_vals, u_vals):\n",
    "  return\n",
    "  final_image = np.zeros((224, 224, 3), dtype = \"uint8\")\n",
    "  final_image[:, :, :] = image[:, :, :]\n",
    "  for i in range(numSegments):\n",
    "    if l_vals[i] < (1.0 / 3):\n",
    "      final_image[masks[i, :, :], :] = 255\n",
    "  cv2.imwrite(\"frames/\" + str(iteration) + \".jpg\", cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR))\n",
    "  images_anim.append(imageio.imread(\"frames/\" + str(iteration) + \".jpg\"))\n",
    "#img_as_float(cv2.resize(io.imread(img_name), (224, 224)))\n",
    "#segments = slic(image1, n_segments = 200, sigma = 0.1)\n",
    "segments = felzenszwalb(image1, scale = 100, sigma = 0.5, min_size = numSegments)\n",
    "\n",
    "#for i in range(224):\n",
    "#  for j in range(224):\n",
    "#    segments[i, j] = i*224 + j\n",
    "#slic(image1, n_segments = numSegments, sigma = 5)\n",
    "numSegments = np.max(segments) + 1\n",
    "print(numSegments)\n",
    "#model = VGG16()\n",
    "#model.summary()\n",
    "image = load_img(img_name, target_size=(224, 224))\n",
    "image = img_to_array(image)\n",
    "orig_image = load_img(img_name)\n",
    "orig_image = img_to_array(orig_image)\n",
    "masks = np.zeros((numSegments, original_image_dims[0], original_image_dims[1]), dtype = bool)\n",
    "for i in range(numSegments):\n",
    "  masks[i, :, :] = (segments == i)\n",
    "class image_class(explain):\n",
    "  iteration = -1\n",
    "  def sampling(self, num_sampled_points):\n",
    "    self.iteration += 1\n",
    "    if (self.iteration % 1000 == 0):\n",
    "      #sample_points(num_sampled_points, self.temp_l_vec_values)\n",
    "      sample_points_1(num_sampled_points)\n",
    "    #samples = np.random.randint(2, size = (num_sampled_points, numSegments))\n",
    "    #odds = [1] * 50 + [2] * 40 + [3] * 10\n",
    "    #indices = np.random.randint(1, total_points, (num_sampled_points))\n",
    "    #indices[0] = 0\n",
    "    #return input_for_explanations[indices, :], class_labels[indices]\n",
    "    return input_for_explanations, class_labels\n",
    "def sample_points_2(num_sampled_points):\n",
    "  global input_for_explanations, class_labels\n",
    "  samples = np.ones((num_sampled_points, numSegments))\n",
    "  for i in range(numSegments):\n",
    "    for j in range(int(num_sampled_points / numSegments)):\n",
    "      samples[np.random.randint(0, num_sampled_points), i] = 0\n",
    "  #for i in range(num_sampled_points):\n",
    "  #  for j in range(int(0.1 * numSegments)):\n",
    "  #    samples[i, random.randint(0, numSegments - 1)] = 0\n",
    "  samples[0, :] = 1\n",
    "  input_for_explanations = samples[:, :] * (1.0 / 3) + (1.0 / 3)\n",
    "  images = np.zeros((num_sampled_points, 224, 224, 3))\n",
    "  samples_boolean = samples.astype(bool)\n",
    "  for i in range(num_sampled_points):\n",
    "    images[i, :, :, :] = image[:, :, :]\n",
    "    images[i, np.any(masks[~samples_boolean[i, :], :, :], 0), :] = 0\n",
    "  images = preprocess_input(images)\n",
    "\n",
    "  #all_predictions = np.zeros((num_sampled_points, 1000))\n",
    "  #for i in range(0, num_sampled_points, 100):\n",
    "  #  all_predictions[i:i+100, :] = model.predict(images[i:i+100, :, :, :])\n",
    "  all_predictions = model.predict(images)\n",
    "  labels = decode_predictions(all_predictions)\n",
    "  class_labels = np.zeros((num_sampled_points, ))\n",
    "  for i in range(num_sampled_points):\n",
    "    for j in range(len(labels[i])):\n",
    "      if labels[i][j][1] == object_label and labels[i][j][2] >= cut_off:\n",
    "        class_labels[i] = 1\n",
    "        break\n",
    "def sample_points_1(num_sampled_points):\n",
    "  global input_for_explanations, class_labels\n",
    "  samples = np.ones((num_sampled_points, numSegments))\n",
    "  for i in range(num_sampled_points):\n",
    "    #parameters_to_be_flipped = np.random.choice(numSegments, int(0.35 * numSegments), replace = False)\n",
    "    #samples[i, parameters_to_be_flipped] = 1 - samples[i, parameters_to_be_flipped]\n",
    "    for j in range(int(0.35 * numSegments)):\n",
    "      samples[i, random.randint(0, numSegments - 1)] = 0\n",
    "  samples[0, :] = 1\n",
    "  input_for_explanations = samples[:, :] * (1.0 / 3) + (1.0 / 3)\n",
    "  images = np.zeros((num_sampled_points, 224, 224, 3))\n",
    "  samples_boolean = samples.astype(bool)\n",
    "  for i in range(num_sampled_points):\n",
    "    images[i, :, :, :] = image[:, :, :]\n",
    "    images[i, cv2.resize(np.any(masks[~samples_boolean[i, :], :, :], 0).astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "  images = preprocess_input(images)\n",
    "\n",
    "  #all_predictions = np.zeros((num_sampled_points, 1000))\n",
    "  #for i in range(0, num_sampled_points, 100):\n",
    "  #  all_predictions[i:i+100, :] = model.predict(images[i:i+100, :, :, :])\n",
    "  all_predictions = model.predict(images)\n",
    "  labels = decode_predictions(all_predictions)\n",
    "  class_labels = np.zeros((num_sampled_points, ))\n",
    "  for i in range(num_sampled_points):\n",
    "    for j in range(len(labels[i])):\n",
    "      if labels[i][j][1] == object_label and labels[i][j][2] >= cut_off:\n",
    "        class_labels[i] = 1\n",
    "        break\n",
    "def sample_points(num_sampled_points, l_vec):\n",
    "  global input_for_explanations, class_labels\n",
    "  samples = np.ones((num_sampled_points, numSegments))\n",
    "  for i in range(numSegments):\n",
    "    if l_vec[i] < (1.0 / 3):\n",
    "      samples[0:(num_sampled_points), i] = np.random.randint(0, 2, ((num_sampled_points), ))\n",
    "      #samples[(num_sampled_points/2):num_sampled_points, i] = 0\n",
    "  for i in range(num_sampled_points / 2):\n",
    "    parameters_to_be_flipped = np.random.choice(numSegments, np.random.randint(1, int(0.5 * numSegments)))\n",
    "    samples[i, parameters_to_be_flipped] = 1 - samples[i, parameters_to_be_flipped]\n",
    "    #np.random.randint(1, int(0.05 * numSegments))\n",
    "    #parameters_to_be_flipped = np.random.choice(numSegments, 1)\n",
    "    #samples[i, parameters_to_be_flipped] = 1 - samples[i, parameters_to_be_flipped]\n",
    "    #for j in range(random.randint(1, int(0.3 * numSegments))):\n",
    "    #  segmentNumber = random.randint(0, numSegments - 1)\n",
    "    #  samples[i, segmentNumber] = 1 - samples[i, segmentNumber]\n",
    "  samples[0, :] = 1\n",
    "  input_for_explanations = np.zeros((num_sampled_points, numSegments))\n",
    "  input_for_explanations[:, :] = samples[:, :] * (1.0 / 3) + (1.0 / 3)\n",
    "  images = np.zeros((num_sampled_points, 224, 224, 3))\n",
    "  samples_boolean = samples.astype(bool)\n",
    "  for i in range(num_sampled_points):\n",
    "    images[i, :, :, :] = image[:, :, :]\n",
    "    images[i, cv2.resize(np.any(masks[~samples_boolean[i, :], :, :], 0).astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "  images = preprocess_input(images)\n",
    "\n",
    "  all_predictions = np.zeros((num_sampled_points, 1000))\n",
    "  for i in range(0, num_sampled_points, 100):\n",
    "    all_predictions[i:i+100, :] = model.predict(images[i:i+100, :, :, :])\n",
    "  labels = decode_predictions(all_predictions)\n",
    "  class_labels = np.zeros((num_sampled_points, ))\n",
    "  for i in range(num_sampled_points):\n",
    "    for j in range(len(labels[i])):\n",
    "      if labels[i][j][1] == object_label and labels[i][j][2] >= cut_off:\n",
    "        class_labels[i] = 1\n",
    "        break\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for run in range(1):\n",
    "  image_object = image_class(np.ones(numSegments, ) * (2.0 / 3), 1000, np.array([[1]]), 100, 100, 0.95, plot_function)\n",
    "  model = VGG16()\n",
    "  image_object.fit_explanation(5000)\n",
    "  final_image = np.zeros((original_image_dims[0], original_image_dims[1], 3), dtype = \"uint8\")\n",
    "  final_image[:, :, :] = orig_image[:, :, :]\n",
    "  test_image = np.zeros((224, 224, 3))\n",
    "  test_image[:, :, :] = image[:, :, :]\n",
    "  for i in range(numSegments):\n",
    "    if image_object.l_vec_values[i] < (1.0 / 3):\n",
    "      final_image[masks[i, :, :], :] = 255\n",
    "      test_image[cv2.resize(masks[i, :, :].astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "  test_images = np.zeros((1, 224, 224, 3))\n",
    "  test_images[0, :, :, :] = test_image[:, :, :]\n",
    "  test_images = preprocess_input(test_images)\n",
    "  print(decode_predictions(model.predict(test_images)))\n",
    "  valid_superpixels = np.ones((numSegments, ), dtype = bool)\n",
    "  valid_superpixels[image_object.l_vec_values < (1.0 / 3)] = 0\n",
    "  cv2.imwrite(path + str(run) + \"_Explanation.jpg\", cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR))\n",
    "  superpixel_removal_order = image_object.greedy_select(numSegments, list(valid_superpixels))\n",
    "  map_importance = np.zeros((original_image_dims[0], original_image_dims[1]))\n",
    "  for i in range(len(superpixel_removal_order)):\n",
    "    map_importance[segments == superpixel_removal_order[i]] = (i + 1) * 1.0 / len(superpixel_removal_order)\n",
    "  heatmap = cv2.applyColorMap(np.uint8(255 * (1 - map_importance)), cv2.COLORMAP_JET)\n",
    "  image_plus_heatmap = cv2.addWeighted(np.uint8(orig_image), 0.2, heatmap, 0.8, 0)\n",
    "  ax.imshow(image_plus_heatmap / 255.0)\n",
    "  plt.axis(\"off\")\n",
    "  plt.savefig(path + str(run) + \"_Heat_Map.jpg\", bbox_inches = \"tight\")\n",
    "  points_graph = 10\n",
    "  images_for_prediction_anchor = np.zeros(((len(superpixel_removal_order) + 1) * points_graph, 224, 224, 3))\n",
    "  images_for_prediction_random = np.zeros(((len(superpixel_removal_order) + 1) * points_graph, 224, 224, 3))\n",
    "  x_anchor = []\n",
    "  x_random = []\n",
    "  y_anchor = []\n",
    "  y_random = []\n",
    "  for i in range(0, len(superpixel_removal_order) + 1):\n",
    "    for j in range(0, points_graph):\n",
    "      images_for_prediction_anchor[i * points_graph + j, :, :, :] = image[:, :, :]\n",
    "      images_for_prediction_random[i * points_graph + j, :, :, :] = image[:, :, :]\n",
    "      random_superpixels = np.random.choice(numSegments, i, replace = False)\n",
    "      anchor_superpixels = np.random.choice(superpixel_removal_order, i, replace = False)\n",
    "      for k in anchor_superpixels:\n",
    "        images_for_prediction_anchor[i * points_graph + j, cv2.resize(masks[k, :, :].astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "      for k in random_superpixels:\n",
    "        images_for_prediction_random[i * points_graph + j, cv2.resize(masks[k, :, :].astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "  images_for_prediction_anchor = preprocess_input(images_for_prediction_anchor)\n",
    "  images_for_prediction_random = preprocess_input(images_for_prediction_random)\n",
    "  predictions_anchor = model.predict(images_for_prediction_anchor)\n",
    "  predictions_random = model.predict(images_for_prediction_random)\n",
    "  decoded_anchor = decode_predictions(predictions_anchor, top = 1000)\n",
    "  decoded_random = decode_predictions(predictions_random, top = 1000)\n",
    "  for i in range(0, len(superpixel_removal_order) + 1):\n",
    "    for j in range(0, points_graph):\n",
    "      x_anchor.append(i)\n",
    "      for k in decoded_anchor[i * points_graph + j]:\n",
    "        if k[1] == object_label:\n",
    "          y_anchor.append(k[2])\n",
    "          break\n",
    "  for i in range(0, len(superpixel_removal_order) + 1):\n",
    "    for j in range(0, points_graph):\n",
    "      x_random.append(i)\n",
    "      for k in decoded_random[i * points_graph + j]:\n",
    "        if k[1] == object_label:\n",
    "          y_random.append(k[2])\n",
    "          break\n",
    "  y_anchor_mean = []\n",
    "  x_mean = []\n",
    "  y_random_mean = []\n",
    "  y_anchor_std = []\n",
    "  y_random_std = []\n",
    "  i = 0\n",
    "  while i < len(y_anchor):\n",
    "    y_anchor_mean.append(np.mean(y_anchor[i:i + points_graph]))\n",
    "    y_random_mean.append(np.mean(y_random[i:i + points_graph]))\n",
    "    y_anchor_std.append(np.std(y_anchor[i:i + points_graph]))\n",
    "    y_random_std.append(np.std(y_random[i:i + points_graph]))\n",
    "    x_mean.append(i / points_graph)\n",
    "    i += points_graph\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  plt.ylabel(\"Confidence Score of VGG16\", fontsize = 18)\n",
    "  plt.xlabel(\"Number of Superpixels Removed\", fontsize = 18)\n",
    "  for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(18) \n",
    "  for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(18)\n",
    "  (_, caps, _) = plt.errorbar(x_mean, y_random_mean, y_random_std, marker = \"o\", color = \"blue\", capsize = 5)\n",
    "  for cap in caps:\n",
    "    cap.set_markeredgewidth(1)\n",
    "  (_, caps, _) = plt.errorbar(x_mean, y_anchor_mean, y_anchor_std, marker = \"o\", color = \"red\", capsize = 5)\n",
    "  for cap in caps:\n",
    "    cap.set_markeredgewidth(1)\n",
    "  ax.legend([\"RSR\", \"MSR\"], fontsize = 18)\n",
    "  plt.axis(\"on\")\n",
    "  plt.savefig(path + str(run) + \"_Probability.pdf\", bbox_inches = \"tight\")\n",
    "  points_graph = 1\n",
    "  images_for_prediction_anchor = np.zeros(((len(superpixel_removal_order) + 1) * points_graph, 224, 224, 3))\n",
    "  images_for_prediction_random = np.zeros(((len(superpixel_removal_order) + 1) * points_graph, 224, 224, 3))\n",
    "  x_anchor = []\n",
    "  y_anchor = []\n",
    "  import copy\n",
    "  superpixel_reverse = copy.deepcopy(superpixel_removal_order)\n",
    "  superpixel_reverse.reverse()\n",
    "  for i in range(0, len(superpixel_removal_order) + 1):\n",
    "    for j in range(0, points_graph):\n",
    "      images_for_prediction_anchor[i * points_graph + j, :, :, :] = image[:, :, :]\n",
    "      anchor_superpixels = superpixel_reverse[0:i]\n",
    "      for k in anchor_superpixels:\n",
    "        images_for_prediction_anchor[i * points_graph + j, cv2.resize(masks[k, :, :].astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "  images_for_prediction_anchor = preprocess_input(images_for_prediction_anchor)\n",
    "  predictions_anchor = model.predict(images_for_prediction_anchor)\n",
    "  decoded_anchor = decode_predictions(predictions_anchor, top = 1000)\n",
    "  for i in range(0, len(superpixel_removal_order) + 1):\n",
    "    for j in range(0, points_graph):\n",
    "      x_anchor.append(i)\n",
    "      for k in decoded_anchor[i * points_graph + j]:\n",
    "        if k[1] == object_label:\n",
    "          y_anchor.append(k[2])\n",
    "          break\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  plt.plot(x_anchor, y_anchor, marker = \"o\")\n",
    "  plt.ylabel(\"Confidence Score of VGG16\", fontsize = 18)\n",
    "  plt.xlabel(\"Number of Superpixels Removed\", fontsize = 18)\n",
    "  for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(18) \n",
    "  for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(18)\n",
    "  plt.axis(\"on\")\n",
    "  plt.savefig(path + str(run) + \"_Greedy.pdf\", bbox_inches = \"tight\")\n",
    "  tf.reset_default_graph()\n",
    "  K.clear_session()\n",
    "imageio.mimsave(\"animations/animation.gif\", images_anim, loop = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MfjeVOd2AGwf",
    "outputId": "98d16589-2a3d-4553-decc-69e0efd6f839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(u'n01795545', u'black_grouse', 0.25314182), (u'n01798484', u'prairie_chicken', 0.10970135), (u'n02088632', u'bluetick', 0.10286375), (u'n03888257', u'parachute', 0.05073037), (u'n01943899', u'conch', 0.033077028)]]\n"
     ]
    }
   ],
   "source": [
    "xp = np.zeros((224, 224, 3))\n",
    "xp[:, :, :] = image[:, :, :]\n",
    "xp[cv2.resize(masks[0, :, :].astype(float), (224, 224), interpolation = 0).astype(bool), :] = 0\n",
    "model = VGG16()\n",
    "image_xp = img_to_array(xp)\n",
    "images_xp = np.zeros((1, 224, 224, 3))\n",
    "images_xp[0, :, :, :] = image_xp[:, :, :]\n",
    "images_xp = preprocess_input(images_xp)\n",
    "predictions = model.predict(images_xp)\n",
    "labels = decode_predictions(predictions)\n",
    "xp_save = np.zeros((500, 500, 3), dtype = \"uint8\")\n",
    "xp_save[:, :, :] = image1[:, :, :]\n",
    "xp_save[masks[0, :, :], :] = 255\n",
    "cv2.imwrite(\"Snow.jpg\", cv2.cvtColor(xp_save, cv2.COLOR_RGB2BGR))\n",
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOHYRx-A6d55"
   },
   "outputs": [],
   "source": [
    "imageio.mimsave(\"animations/animation_endless.gif\", images_anim, loop = 0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MAIRE_Images.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
